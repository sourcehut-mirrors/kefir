.att_syntax
.section .note.GNU-stack,"",%progbits

.global str1_a
.global str1_b
.global str1_c
.global ld_load
.global f32_load
.global f64_load
.global ld_store
.global f32_store
.global f64_store
.global str1_set_a
.global str1_set_b
.global str1_set_c
.global ld_load_index
.global f32_load_index
.global ld_store_index
.global f32_store_index
.global f64_load_index
.global f64_store_index
.extern __kefirrt_opt_amd64_sysv_vararg_save
.extern __kefirrt_opt_load_int_vararg
.extern __kefirrt_opt_load_sse_vararg
.extern __kefirrt_opt_float32_to_uint
.extern __kefirrt_opt_float64_to_uint
.extern __kefirrt_opt_long_double_to_int
.extern __kefirrt_opt_long_double_to_uint
.extern __kefirrt_opt_complex_long_double_equals
.extern __kefirrt_opt_complex_long_double_truncate_1bit
.extern __kefirrt_opt_complex_float32_mul
.extern __kefirrt_opt_complex_float32_div
.extern __kefirrt_opt_complex_float64_mul
.extern __kefirrt_opt_complex_float64_div
.extern __kefirrt_opt_complex_long_double_mul
.extern __kefirrt_opt_complex_long_double_div
.extern __kefirrt_fenv_update
.extern __kefir_opt_float32_neg
.extern __kefir_opt_float64_neg
.extern __kefir_opt_uint2long_double
.extern __kefir_opt_complex_float32_neg
.extern __kefir_opt_complex_float64_neg

.section .text
str1_a:
    push %rbp
    mov %rsp, %rbp
    sub $16, %rsp
    mov %rdi, %rsi
    lea -16(%rbp), %rdx
    mov $8, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movq -16(%rbp), %xmm0
    lea (%rbp), %rsp
    pop %rbp
    ret

str1_b:
    push %rbp
    mov %rsp, %rbp
    sub $32, %rsp
    add $16, %rdi
    mov %rdi, %rsi
    lea -32(%rbp), %rdx
    mov $16, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movq -32(%rbp), %xmm0
    movq -24(%rbp), %xmm1
    lea (%rbp), %rsp
    pop %rbp
    ret

str1_c:
    push %rbp
    mov %rsp, %rbp
    sub $64, %rsp
    add $32, %rdi
    mov %rdi, %rsi
    lea -64(%rbp), %rdx
    mov $32, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    fldt -48(%rbp)
    fldt -64(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret

ld_load:
    push %rbp
    mov %rsp, %rbp
    sub $64, %rsp
    mov %rdi, %rsi
    lea -64(%rbp), %rdx
    mov $32, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    fldt -48(%rbp)
    fldt -64(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret

f32_load:
    push %rbp
    mov %rsp, %rbp
    sub $16, %rsp
    mov %rdi, %rsi
    lea -16(%rbp), %rdx
    mov $8, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movq -16(%rbp), %xmm0
    lea (%rbp), %rsp
    pop %rbp
    ret

f64_load:
    push %rbp
    mov %rsp, %rbp
    sub $32, %rsp
    mov %rdi, %rsi
    lea -32(%rbp), %rdx
    mov $16, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movq -32(%rbp), %xmm0
    movq -24(%rbp), %xmm1
    lea (%rbp), %rsp
    pop %rbp
    ret

ld_store:
    push %rbp
    mov %rsp, %rbp
    sub $112, %rsp
    stmxcsr -8(%rbp)
    lea 16(%rbp), %rax
    lea -80(%rbp), %rcx
    movq $0, 8(%rcx)
    movq $0, 24(%rcx)
    fldt (%rax)
    fstpt (%rcx)
    fldt 16(%rax)
    fstpt 16(%rcx)
    lea -80(%rbp), %rax
    fldt (%rax)
    fstpt -112(%rbp)
    fldt 16(%rax)
    fstpt -96(%rbp)
    mov %rdi, %rsi
    leaq -112(%rbp), %rax
    mov %rax, %rdx
    mov $32, %rdi
    mov $5, %rcx
    call __atomic_store@PLT
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret

f32_store:
    push %rbp
    mov %rsp, %rbp
    sub $32, %rsp
    stmxcsr -8(%rbp)
    movq %xmm0, -32(%rbp)
    lea -24(%rbp), %rax
    movq -32(%rbp), %xmm0
    movq %xmm0, (%rax)
    lea -24(%rbp), %rax
    movq (%rax), %xmm0
    movq %xmm0, -32(%rbp)
    mov %rdi, %rsi
    leaq -32(%rbp), %rax
    mov %rax, %rdx
    mov $8, %rdi
    mov $5, %rcx
    call __atomic_store@PLT
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret

f64_store:
    push %rbp
    mov %rsp, %rbp
    sub $64, %rsp
    stmxcsr -8(%rbp)
    movq %xmm0, -64(%rbp)
    movq %xmm1, -56(%rbp)
    lea -48(%rbp), %rax
    movq -64(%rbp), %xmm0
    movq %xmm0, (%rax)
    movq -56(%rbp), %xmm0
    movq %xmm0, 8(%rax)
    lea -48(%rbp), %rax
    movq (%rax), %xmm0
    movq %xmm0, -64(%rbp)
    movq 8(%rax), %xmm0
    movq %xmm0, -56(%rbp)
    mov %rdi, %rsi
    leaq -64(%rbp), %rax
    mov %rax, %rdx
    mov $16, %rdi
    mov $5, %rcx
    call __atomic_store@PLT
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret

str1_set_a:
    push %rbp
    mov %rsp, %rbp
    sub $32, %rsp
    stmxcsr -8(%rbp)
    movq %xmm0, -32(%rbp)
    lea -24(%rbp), %rax
    movq -32(%rbp), %xmm0
    movq %xmm0, (%rax)
    lea -24(%rbp), %rax
    movq (%rax), %xmm0
    movq %xmm0, -32(%rbp)
    mov %rdi, %rsi
    leaq -32(%rbp), %rax
    mov %rax, %rdx
    mov $8, %rdi
    mov $5, %rcx
    call __atomic_store@PLT
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret

str1_set_b:
    push %rbp
    mov %rsp, %rbp
    sub $64, %rsp
    stmxcsr -8(%rbp)
    movq %xmm0, -64(%rbp)
    movq %xmm1, -56(%rbp)
    lea -48(%rbp), %rax
    movq -64(%rbp), %xmm0
    movq %xmm0, (%rax)
    movq -56(%rbp), %xmm0
    movq %xmm0, 8(%rax)
    lea -48(%rbp), %rax
    movq (%rax), %xmm0
    movq %xmm0, -64(%rbp)
    movq 8(%rax), %xmm0
    movq %xmm0, -56(%rbp)
    add $16, %rdi
    mov %rdi, %rsi
    leaq -64(%rbp), %rax
    mov %rax, %rdx
    mov $16, %rdi
    mov $5, %rcx
    call __atomic_store@PLT
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret

str1_set_c:
    push %rbp
    mov %rsp, %rbp
    sub $112, %rsp
    stmxcsr -8(%rbp)
    lea 16(%rbp), %rax
    lea -80(%rbp), %rcx
    movq $0, 8(%rcx)
    movq $0, 24(%rcx)
    fldt (%rax)
    fstpt (%rcx)
    fldt 16(%rax)
    fstpt 16(%rcx)
    lea -80(%rbp), %rax
    fldt (%rax)
    fstpt -112(%rbp)
    fldt 16(%rax)
    fstpt -96(%rbp)
    add $32, %rdi
    mov %rdi, %rsi
    leaq -112(%rbp), %rax
    mov %rax, %rdx
    mov $32, %rdi
    mov $5, %rcx
    call __atomic_store@PLT
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret

ld_load_index:
    push %rbp
    mov %rsp, %rbp
    sub $64, %rsp
    mov %esi, %eax
    mov %eax, %eax
    imul $32, %rax, %rax
    add %rax, %rdi
    mov %rdi, %rsi
    lea -64(%rbp), %rdx
    mov $32, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    fldt -48(%rbp)
    fldt -64(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret

f32_load_index:
    push %rbp
    mov %rsp, %rbp
    sub $16, %rsp
    mov %esi, %eax
    mov %eax, %eax
    imul $8, %rax, %rax
    add %rax, %rdi
    mov %rdi, %rsi
    lea -16(%rbp), %rdx
    mov $8, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movq -16(%rbp), %xmm0
    lea (%rbp), %rsp
    pop %rbp
    ret

ld_store_index:
    push %rbp
    mov %rsp, %rbp
    sub $112, %rsp
    stmxcsr -8(%rbp)
    lea 16(%rbp), %rax
    lea -80(%rbp), %rcx
    movq $0, 8(%rcx)
    movq $0, 24(%rcx)
    fldt (%rax)
    fstpt (%rcx)
    fldt 16(%rax)
    fstpt 16(%rcx)
    lea -80(%rbp), %rax
    fldt (%rax)
    fstpt -112(%rbp)
    fldt 16(%rax)
    fstpt -96(%rbp)
    mov %esi, %eax
    mov %eax, %eax
    imul $32, %rax, %rax
    add %rax, %rdi
    mov %rdi, %rsi
    leaq -112(%rbp), %rax
    mov %rax, %rdx
    mov $32, %rdi
    mov $5, %rcx
    call __atomic_store@PLT
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret

f32_store_index:
    push %rbp
    mov %rsp, %rbp
    sub $32, %rsp
    stmxcsr -8(%rbp)
    movq %xmm0, -32(%rbp)
    lea -24(%rbp), %rax
    movq -32(%rbp), %xmm0
    movq %xmm0, (%rax)
    lea -24(%rbp), %rax
    movq (%rax), %xmm0
    movq %xmm0, -32(%rbp)
    mov %esi, %eax
    mov %eax, %eax
    imul $8, %rax, %rax
    add %rax, %rdi
    mov %rdi, %rsi
    leaq -32(%rbp), %rax
    mov %rax, %rdx
    mov $8, %rdi
    mov $5, %rcx
    call __atomic_store@PLT
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret

f64_load_index:
    push %rbp
    mov %rsp, %rbp
    sub $32, %rsp
    mov %esi, %eax
    mov %eax, %eax
    imul $16, %rax, %rax
    add %rax, %rdi
    mov %rdi, %rsi
    lea -32(%rbp), %rdx
    mov $16, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movq -32(%rbp), %xmm0
    movq -24(%rbp), %xmm1
    lea (%rbp), %rsp
    pop %rbp
    ret

f64_store_index:
    push %rbp
    mov %rsp, %rbp
    sub $64, %rsp
    stmxcsr -8(%rbp)
    movq %xmm0, -64(%rbp)
    movq %xmm1, -56(%rbp)
    lea -48(%rbp), %rax
    movq -64(%rbp), %xmm0
    movq %xmm0, (%rax)
    movq -56(%rbp), %xmm0
    movq %xmm0, 8(%rax)
    lea -48(%rbp), %rax
    movq (%rax), %xmm0
    movq %xmm0, -64(%rbp)
    movq 8(%rax), %xmm0
    movq %xmm0, -56(%rbp)
    mov %esi, %eax
    mov %eax, %eax
    imul $16, %rax, %rax
    add %rax, %rdi
    mov %rdi, %rsi
    leaq -64(%rbp), %rax
    mov %rax, %rdx
    mov $16, %rdi
    mov $5, %rcx
    call __atomic_store@PLT
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret


