.att_syntax
.section .note.GNU-stack,"",%progbits

.global add_f32
.type add_f32, @function
.global add_f64
.type add_f64, @function
.global divide_f32
.type divide_f32, @function
.global divide_f64
.type divide_f64, @function
.global multiply_f32
.type multiply_f32, @function
.global multiply_f64
.type multiply_f64, @function
.global subtract_f32
.type subtract_f32, @function
.global subtract_f64
.type subtract_f64, @function

.section .text
__kefir_text_section_begin:
add_f32:
__kefir_text_func_add_f32_begin:
    push %rbp
    mov %rsp, %rbp
    sub $192, %rsp
    stmxcsr -8(%rbp)
    movaps %xmm0, %xmm1
    shufps $1, %xmm1, %xmm1
    mov %rdi, %r10
    movd %xmm0, -16(%rbp)
    movd %xmm1, -12(%rbp)
    movd -16(%rbp), %xmm4
    movd -12(%rbp), %xmm5
    fnstenv -168(%rbp)
    stmxcsr -140(%rbp)
    fnclex
_kefir_func_add_f32_label1:
    movq %r10, -136(%rbp)
    movdqu %xmm4, -128(%rbp)
    movdqu %xmm5, -112(%rbp)
    mov %r10, %rsi
    lea -192(%rbp), %rdx
    mov $8, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movq -136(%rbp), %r10
    movdqu -128(%rbp), %xmm4
    movdqu -112(%rbp), %xmm5
    movd -192(%rbp), %xmm0
    movd -188(%rbp), %xmm1
    movq %xmm0, %xmm2
    movq %xmm1, %xmm3
    addss %xmm4, %xmm2
    addss %xmm5, %xmm3
    movq %r10, -96(%rbp)
    movdqu %xmm4, -88(%rbp)
    movdqu %xmm5, -72(%rbp)
    movdqu %xmm2, -56(%rbp)
    movdqu %xmm3, -40(%rbp)
    movd %xmm0, -192(%rbp)
    movd %xmm1, -188(%rbp)
    movd %xmm2, -184(%rbp)
    movd %xmm3, -180(%rbp)
    mov %r10, %rsi
    mov $5, %r8
    mov $5, %r9
    mov $8, %rdi
    lea -192(%rbp), %rdx
    leaq -184(%rbp), %rax
    mov %rax, %rcx
    call __atomic_compare_exchange@PLT
    movq -96(%rbp), %r10
    movdqu -88(%rbp), %xmm4
    movdqu -72(%rbp), %xmm5
    movdqu -56(%rbp), %xmm2
    movdqu -40(%rbp), %xmm3
    test %al, %al
    jz _kefir_func_add_f32_label3
    stmxcsr -192(%rbp)
    mov -192(%rbp), %rcx
    fnstsw %ax
    or %ecx, %eax
    and $63, %eax
    fldenv -168(%rbp)
    ldmxcsr -140(%rbp)
    stmxcsr -192(%rbp)
    orl %eax, -192(%rbp)
    ldmxcsr -192(%rbp)
    movq %xmm2, %xmm0
    insertps $16, %xmm3, %xmm0
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret
_kefir_func_add_f32_label3:
    fnclex
    jmp _kefir_func_add_f32_label1
__kefir_text_func_add_f32_end:

add_f64:
__kefir_text_func_add_f64_begin:
    push %rbp
    mov %rsp, %rbp
    sub $144, %rsp
    stmxcsr -8(%rbp)
    movq %xmm0, -96(%rbp)
    movq %xmm1, -88(%rbp)
    mov %rdi, %r10
    movq -96(%rbp), %xmm0
    movq %xmm0, -24(%rbp)
    movq -88(%rbp), %xmm0
    movq %xmm0, -16(%rbp)
    movq -24(%rbp), %xmm0
    movq %xmm0, -80(%rbp)
    movq -16(%rbp), %xmm0
    movq %xmm0, -72(%rbp)
    fnstenv -64(%rbp)
    stmxcsr -36(%rbp)
    fnclex
_kefir_func_add_f64_label1:
    movq %r10, -128(%rbp)
    mov %r10, %rsi
    lea -144(%rbp), %rdx
    mov $16, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movq -128(%rbp), %r10
    movq -144(%rbp), %xmm0
    movq -136(%rbp), %xmm1
    addsd -80(%rbp), %xmm0
    addsd -72(%rbp), %xmm1
    movq %xmm0, -112(%rbp)
    movq %xmm1, -104(%rbp)
    movq %r10, -32(%rbp)
    movdqu -144(%rbp), %xmm0
    movdqu %xmm0, -128(%rbp)
    mov %r10, %rsi
    mov $5, %r8
    mov $5, %r9
    mov $16, %rdi
    lea -128(%rbp), %rdx
    leaq -112(%rbp), %rax
    mov %rax, %rcx
    call __atomic_compare_exchange@PLT
    movq -32(%rbp), %r10
    test %al, %al
    jz _kefir_func_add_f64_label3
    stmxcsr -144(%rbp)
    mov -144(%rbp), %rdx
    fnstsw %ax
    or %edx, %eax
    and $63, %eax
    fldenv -64(%rbp)
    ldmxcsr -36(%rbp)
    stmxcsr -144(%rbp)
    orl %eax, -144(%rbp)
    ldmxcsr -144(%rbp)
    movq -112(%rbp), %xmm0
    movq -104(%rbp), %xmm1
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret
_kefir_func_add_f64_label3:
    fnclex
    jmp _kefir_func_add_f64_label1
__kefir_text_func_add_f64_end:

divide_f32:
__kefir_text_func_divide_f32_begin:
    push %rbp
    mov %rsp, %rbp
    sub $192, %rsp
    stmxcsr -8(%rbp)
    movaps %xmm0, %xmm1
    shufps $1, %xmm1, %xmm1
    mov %rdi, %r10
    movd %xmm0, -16(%rbp)
    movd %xmm1, -12(%rbp)
    movd -16(%rbp), %xmm7
    movd -12(%rbp), %xmm8
    fnstenv -176(%rbp)
    stmxcsr -148(%rbp)
    fnclex
_kefir_func_divide_f32_label1:
    movq %r10, -136(%rbp)
    movdqu %xmm7, -128(%rbp)
    movdqu %xmm8, -112(%rbp)
    mov %r10, %rsi
    lea -192(%rbp), %rdx
    mov $8, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movq -136(%rbp), %r10
    movdqu -128(%rbp), %xmm7
    movdqu -112(%rbp), %xmm8
    movd -192(%rbp), %xmm1
    movd -188(%rbp), %xmm2
    movq %xmm1, %xmm0
    insertps $16, %xmm2, %xmm0
    movq %xmm7, %xmm3
    insertps $16, %xmm8, %xmm3
    cvtps2pd %xmm3, %xmm4
    cvtps2pd %xmm0, %xmm0
    movaps %xmm4, %xmm5
    movaps %xmm4, %xmm6
    unpcklpd %xmm4, %xmm5
    mulpd %xmm0, %xmm5
    shufpd $1, %xmm0, %xmm0
    unpckhpd %xmm4, %xmm6
    mulpd %xmm4, %xmm4
    mulpd %xmm6, %xmm0
    movaps %xmm4, %xmm6
    xorps __kefir_constant_complex_float32_div(%rip), %xmm0
    shufpd $1, %xmm4, %xmm6
    addpd %xmm0, %xmm5
    addpd %xmm6, %xmm4
    divpd %xmm4, %xmm5
    cvtpd2ps %xmm5, %xmm0
    movaps %xmm0, %xmm4
    shufps $1, %xmm4, %xmm4
    movq %r10, -96(%rbp)
    movdqu %xmm7, -88(%rbp)
    movdqu %xmm8, -72(%rbp)
    movdqu %xmm0, -56(%rbp)
    movdqu %xmm4, -40(%rbp)
    movd %xmm1, -192(%rbp)
    movd %xmm2, -188(%rbp)
    movd %xmm0, -184(%rbp)
    movd %xmm4, -180(%rbp)
    mov %r10, %rsi
    mov $5, %r8
    mov $5, %r9
    mov $8, %rdi
    lea -192(%rbp), %rdx
    leaq -184(%rbp), %rax
    mov %rax, %rcx
    call __atomic_compare_exchange@PLT
    movq -96(%rbp), %r10
    movdqu -88(%rbp), %xmm7
    movdqu -72(%rbp), %xmm8
    movdqu -56(%rbp), %xmm0
    movdqu -40(%rbp), %xmm4
    test %al, %al
    jz _kefir_func_divide_f32_label3
    stmxcsr -192(%rbp)
    mov -192(%rbp), %rcx
    fnstsw %ax
    or %ecx, %eax
    and $63, %eax
    fldenv -176(%rbp)
    ldmxcsr -148(%rbp)
    stmxcsr -192(%rbp)
    orl %eax, -192(%rbp)
    ldmxcsr -192(%rbp)
    insertps $16, %xmm4, %xmm0
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret
_kefir_func_divide_f32_label3:
    fnclex
    jmp _kefir_func_divide_f32_label1
__kefir_text_func_divide_f32_end:

divide_f64:
__kefir_text_func_divide_f64_begin:
    push %rbp
    mov %rsp, %rbp
    sub $144, %rsp
    stmxcsr -8(%rbp)
    movq %xmm0, -48(%rbp)
    movq %xmm1, -40(%rbp)
    mov %rdi, %r10
    movq -48(%rbp), %xmm0
    movq %xmm0, -24(%rbp)
    movq -40(%rbp), %xmm0
    movq %xmm0, -16(%rbp)
    movq -24(%rbp), %xmm0
    movq %xmm0, -96(%rbp)
    movq -16(%rbp), %xmm0
    movq %xmm0, -88(%rbp)
    fnstenv -80(%rbp)
    stmxcsr -52(%rbp)
    fnclex
_kefir_func_divide_f64_label1:
    movq %r10, -144(%rbp)
    mov %r10, %rsi
    lea -128(%rbp), %rdx
    mov $16, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movq -144(%rbp), %r10
    fld1
    fldl -96(%rbp)
    fld %st(0)
    fmul %st(1)
    fldl -88(%rbp)
    fld %st(0)
    fmul %st(1)
    faddp %st(2)
    fxch %st(1)
    fdivrp %st(3)
    fldl -128(%rbp)
    fld %st(0)
    fmul %st(3)
    fxch %st(1)
    fmul %st(2)
    fldl -120(%rbp)
    fld %st(0)
    fmulp %st(4)
    fxch %st(3)
    faddp %st(2)
    fxch %st(1)
    fmul %st(4)
    fstpl -112(%rbp)
    fxch %st(2)
    fmulp %st(1)
    fsubp
    fmulp
    fstpl -104(%rbp)
    movq %r10, -32(%rbp)
    movdqu -128(%rbp), %xmm0
    movdqu %xmm0, -144(%rbp)
    mov %r10, %rsi
    mov $5, %r8
    mov $5, %r9
    mov $16, %rdi
    lea -144(%rbp), %rdx
    leaq -112(%rbp), %rax
    mov %rax, %rcx
    call __atomic_compare_exchange@PLT
    movq -32(%rbp), %r10
    test %al, %al
    jz _kefir_func_divide_f64_label3
    stmxcsr -144(%rbp)
    mov -144(%rbp), %rdx
    fnstsw %ax
    or %edx, %eax
    and $63, %eax
    fldenv -80(%rbp)
    ldmxcsr -52(%rbp)
    stmxcsr -144(%rbp)
    orl %eax, -144(%rbp)
    ldmxcsr -144(%rbp)
    movq -112(%rbp), %xmm0
    movq -104(%rbp), %xmm1
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret
_kefir_func_divide_f64_label3:
    fnclex
    jmp _kefir_func_divide_f64_label1
__kefir_text_func_divide_f64_end:

multiply_f32:
__kefir_text_func_multiply_f32_begin:
    push %rbp
    mov %rsp, %rbp
    sub $192, %rsp
    stmxcsr -8(%rbp)
    movaps %xmm0, %xmm1
    shufps $1, %xmm1, %xmm1
    mov %rdi, %r10
    movd %xmm0, -16(%rbp)
    movd %xmm1, -12(%rbp)
    movd -16(%rbp), %xmm5
    movd -12(%rbp), %xmm6
    fnstenv -176(%rbp)
    stmxcsr -148(%rbp)
    fnclex
_kefir_func_multiply_f32_label1:
    movq %r10, -136(%rbp)
    movdqu %xmm5, -128(%rbp)
    movdqu %xmm6, -112(%rbp)
    mov %r10, %rsi
    lea -192(%rbp), %rdx
    mov $8, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movq -136(%rbp), %r10
    movdqu -128(%rbp), %xmm5
    movdqu -112(%rbp), %xmm6
    movd -192(%rbp), %xmm0
    movd -188(%rbp), %xmm1
    movq %xmm0, %xmm2
    insertps $16, %xmm1, %xmm2
    movq %xmm5, %xmm3
    insertps $16, %xmm6, %xmm3
    movaps %xmm3, %xmm4
    shufps $160, %xmm3, %xmm4
    mulps %xmm2, %xmm4
    xorps __kefir_constant_complex_float32_mul(%rip), %xmm2
    shufps $177, %xmm2, %xmm2
    shufps $245, %xmm3, %xmm3
    mulps %xmm3, %xmm2
    addps %xmm4, %xmm2
    movaps %xmm2, %xmm4
    shufps $1, %xmm4, %xmm4
    movq %r10, -96(%rbp)
    movdqu %xmm5, -88(%rbp)
    movdqu %xmm6, -72(%rbp)
    movdqu %xmm2, -56(%rbp)
    movdqu %xmm4, -40(%rbp)
    movd %xmm0, -192(%rbp)
    movd %xmm1, -188(%rbp)
    movd %xmm2, -184(%rbp)
    movd %xmm4, -180(%rbp)
    mov %r10, %rsi
    mov $5, %r8
    mov $5, %r9
    mov $8, %rdi
    lea -192(%rbp), %rdx
    leaq -184(%rbp), %rax
    mov %rax, %rcx
    call __atomic_compare_exchange@PLT
    movq -96(%rbp), %r10
    movdqu -88(%rbp), %xmm5
    movdqu -72(%rbp), %xmm6
    movdqu -56(%rbp), %xmm2
    movdqu -40(%rbp), %xmm4
    test %al, %al
    jz _kefir_func_multiply_f32_label3
    stmxcsr -192(%rbp)
    mov -192(%rbp), %rcx
    fnstsw %ax
    or %ecx, %eax
    and $63, %eax
    fldenv -176(%rbp)
    ldmxcsr -148(%rbp)
    stmxcsr -192(%rbp)
    orl %eax, -192(%rbp)
    ldmxcsr -192(%rbp)
    movq %xmm2, %xmm0
    insertps $16, %xmm4, %xmm0
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret
_kefir_func_multiply_f32_label3:
    fnclex
    jmp _kefir_func_multiply_f32_label1
__kefir_text_func_multiply_f32_end:

multiply_f64:
__kefir_text_func_multiply_f64_begin:
    push %rbp
    mov %rsp, %rbp
    sub $144, %rsp
    stmxcsr -8(%rbp)
    movq %xmm0, -48(%rbp)
    movq %xmm1, -40(%rbp)
    mov %rdi, %r10
    movq -48(%rbp), %xmm0
    movq %xmm0, -24(%rbp)
    movq -40(%rbp), %xmm0
    movq %xmm0, -16(%rbp)
    movq -24(%rbp), %xmm0
    movq %xmm0, -96(%rbp)
    movq -16(%rbp), %xmm0
    movq %xmm0, -88(%rbp)
    fnstenv -80(%rbp)
    stmxcsr -52(%rbp)
    fnclex
_kefir_func_multiply_f64_label1:
    movq %r10, -128(%rbp)
    mov %r10, %rsi
    lea -144(%rbp), %rdx
    mov $16, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movq -128(%rbp), %r10
    movq -144(%rbp), %xmm0
    movq -136(%rbp), %xmm1
    movq -96(%rbp), %xmm2
    movq -88(%rbp), %xmm3
    unpcklpd %xmm1, %xmm0
    movaps %xmm0, %xmm1
    xorps __kefir_constant_complex_float64_mul(%rip), %xmm1
    shufpd $1, %xmm1, %xmm1
    unpcklpd %xmm2, %xmm2
    unpcklpd %xmm3, %xmm3
    mulpd %xmm0, %xmm2
    mulpd %xmm1, %xmm3
    addpd %xmm2, %xmm3
    movaps %xmm3, %xmm0
    movaps %xmm3, %xmm1
    unpckhpd %xmm3, %xmm0
    movq %xmm1, -112(%rbp)
    movq %xmm0, -104(%rbp)
    movq %r10, -32(%rbp)
    movdqu -144(%rbp), %xmm0
    movdqu %xmm0, -128(%rbp)
    mov %r10, %rsi
    mov $5, %r8
    mov $5, %r9
    mov $16, %rdi
    lea -128(%rbp), %rdx
    leaq -112(%rbp), %rax
    mov %rax, %rcx
    call __atomic_compare_exchange@PLT
    movq -32(%rbp), %r10
    test %al, %al
    jz _kefir_func_multiply_f64_label3
    stmxcsr -144(%rbp)
    mov -144(%rbp), %rdx
    fnstsw %ax
    or %edx, %eax
    and $63, %eax
    fldenv -80(%rbp)
    ldmxcsr -52(%rbp)
    stmxcsr -144(%rbp)
    orl %eax, -144(%rbp)
    ldmxcsr -144(%rbp)
    movq -112(%rbp), %xmm0
    movq -104(%rbp), %xmm1
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret
_kefir_func_multiply_f64_label3:
    fnclex
    jmp _kefir_func_multiply_f64_label1
__kefir_text_func_multiply_f64_end:

subtract_f32:
__kefir_text_func_subtract_f32_begin:
    push %rbp
    mov %rsp, %rbp
    sub $192, %rsp
    stmxcsr -8(%rbp)
    movaps %xmm0, %xmm1
    shufps $1, %xmm1, %xmm1
    mov %rdi, %r10
    movd %xmm0, -16(%rbp)
    movd %xmm1, -12(%rbp)
    movd -16(%rbp), %xmm4
    movd -12(%rbp), %xmm5
    fnstenv -168(%rbp)
    stmxcsr -140(%rbp)
    fnclex
_kefir_func_subtract_f32_label1:
    movq %r10, -136(%rbp)
    movdqu %xmm4, -128(%rbp)
    movdqu %xmm5, -112(%rbp)
    mov %r10, %rsi
    lea -192(%rbp), %rdx
    mov $8, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movq -136(%rbp), %r10
    movdqu -128(%rbp), %xmm4
    movdqu -112(%rbp), %xmm5
    movd -192(%rbp), %xmm0
    movd -188(%rbp), %xmm1
    movq %xmm0, %xmm2
    movq %xmm1, %xmm3
    subss %xmm4, %xmm2
    subss %xmm5, %xmm3
    movq %r10, -96(%rbp)
    movdqu %xmm4, -88(%rbp)
    movdqu %xmm5, -72(%rbp)
    movdqu %xmm2, -56(%rbp)
    movdqu %xmm3, -40(%rbp)
    movd %xmm0, -192(%rbp)
    movd %xmm1, -188(%rbp)
    movd %xmm2, -184(%rbp)
    movd %xmm3, -180(%rbp)
    mov %r10, %rsi
    mov $5, %r8
    mov $5, %r9
    mov $8, %rdi
    lea -192(%rbp), %rdx
    leaq -184(%rbp), %rax
    mov %rax, %rcx
    call __atomic_compare_exchange@PLT
    movq -96(%rbp), %r10
    movdqu -88(%rbp), %xmm4
    movdqu -72(%rbp), %xmm5
    movdqu -56(%rbp), %xmm2
    movdqu -40(%rbp), %xmm3
    test %al, %al
    jz _kefir_func_subtract_f32_label3
    stmxcsr -192(%rbp)
    mov -192(%rbp), %rcx
    fnstsw %ax
    or %ecx, %eax
    and $63, %eax
    fldenv -168(%rbp)
    ldmxcsr -140(%rbp)
    stmxcsr -192(%rbp)
    orl %eax, -192(%rbp)
    ldmxcsr -192(%rbp)
    movq %xmm2, %xmm0
    insertps $16, %xmm3, %xmm0
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret
_kefir_func_subtract_f32_label3:
    fnclex
    jmp _kefir_func_subtract_f32_label1
__kefir_text_func_subtract_f32_end:

subtract_f64:
__kefir_text_func_subtract_f64_begin:
    push %rbp
    mov %rsp, %rbp
    sub $144, %rsp
    stmxcsr -8(%rbp)
    movq %xmm0, -96(%rbp)
    movq %xmm1, -88(%rbp)
    mov %rdi, %r10
    movq -96(%rbp), %xmm0
    movq %xmm0, -24(%rbp)
    movq -88(%rbp), %xmm0
    movq %xmm0, -16(%rbp)
    movq -24(%rbp), %xmm0
    movq %xmm0, -80(%rbp)
    movq -16(%rbp), %xmm0
    movq %xmm0, -72(%rbp)
    fnstenv -64(%rbp)
    stmxcsr -36(%rbp)
    fnclex
_kefir_func_subtract_f64_label1:
    movq %r10, -128(%rbp)
    mov %r10, %rsi
    lea -144(%rbp), %rdx
    mov $16, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movq -128(%rbp), %r10
    movq -144(%rbp), %xmm0
    movq -136(%rbp), %xmm1
    subsd -80(%rbp), %xmm0
    subsd -72(%rbp), %xmm1
    movq %xmm0, -112(%rbp)
    movq %xmm1, -104(%rbp)
    movq %r10, -32(%rbp)
    movdqu -144(%rbp), %xmm0
    movdqu %xmm0, -128(%rbp)
    mov %r10, %rsi
    mov $5, %r8
    mov $5, %r9
    mov $16, %rdi
    lea -128(%rbp), %rdx
    leaq -112(%rbp), %rax
    mov %rax, %rcx
    call __atomic_compare_exchange@PLT
    movq -32(%rbp), %r10
    test %al, %al
    jz _kefir_func_subtract_f64_label3
    stmxcsr -144(%rbp)
    mov -144(%rbp), %rdx
    fnstsw %ax
    or %edx, %eax
    and $63, %eax
    fldenv -64(%rbp)
    ldmxcsr -36(%rbp)
    stmxcsr -144(%rbp)
    orl %eax, -144(%rbp)
    ldmxcsr -144(%rbp)
    movq -112(%rbp), %xmm0
    movq -104(%rbp), %xmm1
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret
_kefir_func_subtract_f64_label3:
    fnclex
    jmp _kefir_func_subtract_f64_label1
__kefir_text_func_subtract_f64_end:

__kefir_text_section_end:

.section .rodata
    .align 16
__kefir_constant_complex_float32_mul:
    .long 0
    .long 2147483648
    .long 0
    .long 2147483648
    .align 16
__kefir_constant_complex_float32_div:
    .long 0
    .long 0
    .long 0
    .long 2147483648
    .align 16
__kefir_constant_complex_float64_mul:
    .long 0
    .long 0
    .long 0
    .long 2147483648
