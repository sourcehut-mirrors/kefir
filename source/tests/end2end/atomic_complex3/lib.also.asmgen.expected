.att_syntax
.section .note.GNU-stack,"",%progbits

.global add_f32
.type add_f32, @function
.global add_f64
.type add_f64, @function
.global divide_f32
.type divide_f32, @function
.global divide_f64
.type divide_f64, @function
.global multiply_f32
.type multiply_f32, @function
.global multiply_f64
.type multiply_f64, @function
.global subtract_f32
.type subtract_f32, @function
.global subtract_f64
.type subtract_f64, @function

.section .text
__kefir_text_section_begin:
add_f32:
__kefir_text_func_add_f32_begin:
    push %rbp
    mov %rsp, %rbp
    sub $128, %rsp
    stmxcsr -8(%rbp)
    movq %xmm0, -128(%rbp)
    lea -24(%rbp), %rax
    movq -128(%rbp), %xmm0
    movq %xmm0, (%rax)
    lea -24(%rbp), %rax
    movq (%rax), %xmm0
    movq %xmm0, -128(%rbp)
    fnstenv -120(%rbp)
    stmxcsr -92(%rbp)
    fnclex
    mov %rdi, %r10
_kefir_func_add_f32_label2:
    movq %r10, -80(%rbp)
    mov %r10, %rsi
    lea -88(%rbp), %rdx
    mov $8, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movq -80(%rbp), %r10
    movd -88(%rbp), %xmm0
    movd -84(%rbp), %xmm1
    addss -128(%rbp), %xmm0
    addss -124(%rbp), %xmm1
    movd %xmm0, -80(%rbp)
    movd %xmm1, -76(%rbp)
    movq %r10, -64(%rbp)
    movq -88(%rbp), %rax
    movq %rax, -72(%rbp)
    mov %r10, %rsi
    mov $5, %r8
    mov $5, %r9
    mov $8, %rdi
    lea -72(%rbp), %rdx
    leaq -80(%rbp), %rax
    mov %rax, %rcx
    call __atomic_compare_exchange@PLT
    movq -64(%rbp), %r10
    test %al, %al
    jz _kefir_func_add_f32_label5
    movq -120(%rbp), %rax
    movq %rax, -56(%rbp)
    movq -112(%rbp), %rax
    movq %rax, -48(%rbp)
    movq -104(%rbp), %rax
    movq %rax, -40(%rbp)
    movq -96(%rbp), %rax
    movq %rax, -32(%rbp)
    jmp _kefir_func_add_f32_label4
_kefir_func_add_f32_label5:
    mov %r10, %rax
    movq -128(%rbp), %rcx
    movq %rcx, -88(%rbp)
    movq -120(%rbp), %rcx
    movq %rcx, -72(%rbp)
    movq -112(%rbp), %rcx
    movq %rcx, -64(%rbp)
    movq -104(%rbp), %rcx
    movq %rcx, -56(%rbp)
    movq -96(%rbp), %rcx
    movq %rcx, -48(%rbp)
    fnclex
    mov %rax, %r10
    movq -88(%rbp), %rax
    movq %rax, -128(%rbp)
    movq -72(%rbp), %rax
    movq %rax, -120(%rbp)
    movq -64(%rbp), %rax
    movq %rax, -112(%rbp)
    movq -56(%rbp), %rax
    movq %rax, -104(%rbp)
    movq -48(%rbp), %rax
    movq %rax, -96(%rbp)
    jmp _kefir_func_add_f32_label2
_kefir_func_add_f32_label4:
    stmxcsr -128(%rbp)
    mov -128(%rbp), %rcx
    fnstsw %ax
    or %ecx, %eax
    and $63, %eax
    fldenv -56(%rbp)
    ldmxcsr -28(%rbp)
    stmxcsr -128(%rbp)
    movl -128(%rbp), %ecx
    or %eax, %ecx
    movl %ecx, -128(%rbp)
    ldmxcsr -128(%rbp)
    movq -80(%rbp), %xmm0
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret
__kefir_text_func_add_f32_end:

add_f64:
__kefir_text_func_add_f64_begin:
    push %rbp
    mov %rsp, %rbp
    sub $192, %rsp
    stmxcsr -8(%rbp)
    movq %xmm0, -192(%rbp)
    movq %xmm1, -184(%rbp)
    lea -48(%rbp), %rax
    movq -192(%rbp), %xmm0
    movq %xmm0, (%rax)
    movq -184(%rbp), %xmm0
    movq %xmm0, 8(%rax)
    lea -48(%rbp), %rax
    movq (%rax), %xmm0
    movq %xmm0, -192(%rbp)
    movq 8(%rax), %xmm0
    movq %xmm0, -184(%rbp)
    fnstenv -176(%rbp)
    stmxcsr -148(%rbp)
    fnclex
    mov %rdi, %r10
_kefir_func_add_f64_label2:
    movq %r10, -128(%rbp)
    mov %r10, %rsi
    lea -144(%rbp), %rdx
    mov $16, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movq -128(%rbp), %r10
    movq -144(%rbp), %xmm0
    movq -136(%rbp), %xmm1
    addsd -192(%rbp), %xmm0
    addsd -184(%rbp), %xmm1
    movq %xmm0, -120(%rbp)
    movq %xmm1, -112(%rbp)
    movq %r10, -128(%rbp)
    movdqu -144(%rbp), %xmm0
    movdqu %xmm0, -104(%rbp)
    mov %r10, %rsi
    mov $5, %r8
    mov $5, %r9
    mov $16, %rdi
    lea -104(%rbp), %rdx
    leaq -120(%rbp), %rax
    mov %rax, %rcx
    call __atomic_compare_exchange@PLT
    movq -128(%rbp), %r10
    test %al, %al
    jz _kefir_func_add_f64_label5
    movq -176(%rbp), %rax
    movq %rax, -88(%rbp)
    movq -168(%rbp), %rax
    movq %rax, -80(%rbp)
    movq -160(%rbp), %rax
    movq %rax, -72(%rbp)
    movq -152(%rbp), %rax
    movq %rax, -64(%rbp)
    jmp _kefir_func_add_f64_label4
_kefir_func_add_f64_label5:
    mov %r10, %rax
    movq -192(%rbp), %rcx
    movq %rcx, -144(%rbp)
    movq -184(%rbp), %rcx
    movq %rcx, -136(%rbp)
    movq -176(%rbp), %rcx
    movq %rcx, -104(%rbp)
    movq -168(%rbp), %rcx
    movq %rcx, -96(%rbp)
    movq -160(%rbp), %rcx
    movq %rcx, -88(%rbp)
    movq -152(%rbp), %rcx
    movq %rcx, -80(%rbp)
    fnclex
    mov %rax, %r10
    movq -144(%rbp), %rax
    movq %rax, -192(%rbp)
    movq -136(%rbp), %rax
    movq %rax, -184(%rbp)
    movq -104(%rbp), %rax
    movq %rax, -176(%rbp)
    movq -96(%rbp), %rax
    movq %rax, -168(%rbp)
    movq -88(%rbp), %rax
    movq %rax, -160(%rbp)
    movq -80(%rbp), %rax
    movq %rax, -152(%rbp)
    jmp _kefir_func_add_f64_label2
_kefir_func_add_f64_label4:
    stmxcsr -192(%rbp)
    mov -192(%rbp), %rcx
    fnstsw %ax
    or %ecx, %eax
    and $63, %eax
    fldenv -88(%rbp)
    ldmxcsr -60(%rbp)
    stmxcsr -192(%rbp)
    movl -192(%rbp), %ecx
    or %eax, %ecx
    movl %ecx, -192(%rbp)
    ldmxcsr -192(%rbp)
    movq -120(%rbp), %xmm0
    movq -112(%rbp), %xmm1
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret
__kefir_text_func_add_f64_end:

divide_f32:
__kefir_text_func_divide_f32_begin:
    push %rbp
    mov %rsp, %rbp
    sub $128, %rsp
    stmxcsr -8(%rbp)
    movq %xmm0, -128(%rbp)
    lea -24(%rbp), %rax
    movq -128(%rbp), %xmm0
    movq %xmm0, (%rax)
    lea -24(%rbp), %rax
    movq (%rax), %xmm0
    movq %xmm0, -128(%rbp)
    fnstenv -120(%rbp)
    stmxcsr -92(%rbp)
    fnclex
    mov %rdi, %r10
_kefir_func_divide_f32_label2:
    movq %r10, -80(%rbp)
    mov %r10, %rsi
    lea -88(%rbp), %rdx
    mov $8, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movq -80(%rbp), %r10
    movq -88(%rbp), %xmm0
    movq -128(%rbp), %xmm1
    cvtps2pd %xmm1, %xmm1
    cvtps2pd %xmm0, %xmm0
    movaps %xmm1, %xmm2
    movaps %xmm1, %xmm3
    unpcklpd %xmm1, %xmm2
    mulpd %xmm0, %xmm2
    shufpd $1, %xmm0, %xmm0
    unpckhpd %xmm1, %xmm3
    mulpd %xmm1, %xmm1
    mulpd %xmm3, %xmm0
    movaps %xmm1, %xmm3
    xorps __kefir_constant_complex_float32_div(%rip), %xmm0
    shufpd $1, %xmm1, %xmm3
    addpd %xmm0, %xmm2
    addpd %xmm3, %xmm1
    divpd %xmm1, %xmm2
    cvtpd2ps %xmm2, %xmm0
    movq %xmm0, -80(%rbp)
    movq %r10, -64(%rbp)
    movq -88(%rbp), %rax
    movq %rax, -72(%rbp)
    mov %r10, %rsi
    mov $5, %r8
    mov $5, %r9
    mov $8, %rdi
    lea -72(%rbp), %rdx
    leaq -80(%rbp), %rax
    mov %rax, %rcx
    call __atomic_compare_exchange@PLT
    movq -64(%rbp), %r10
    test %al, %al
    jz _kefir_func_divide_f32_label5
    movq -120(%rbp), %rax
    movq %rax, -56(%rbp)
    movq -112(%rbp), %rax
    movq %rax, -48(%rbp)
    movq -104(%rbp), %rax
    movq %rax, -40(%rbp)
    movq -96(%rbp), %rax
    movq %rax, -32(%rbp)
    jmp _kefir_func_divide_f32_label4
_kefir_func_divide_f32_label5:
    mov %r10, %rax
    movq -128(%rbp), %rcx
    movq %rcx, -88(%rbp)
    movq -120(%rbp), %rcx
    movq %rcx, -72(%rbp)
    movq -112(%rbp), %rcx
    movq %rcx, -64(%rbp)
    movq -104(%rbp), %rcx
    movq %rcx, -56(%rbp)
    movq -96(%rbp), %rcx
    movq %rcx, -48(%rbp)
    fnclex
    mov %rax, %r10
    movq -88(%rbp), %rax
    movq %rax, -128(%rbp)
    movq -72(%rbp), %rax
    movq %rax, -120(%rbp)
    movq -64(%rbp), %rax
    movq %rax, -112(%rbp)
    movq -56(%rbp), %rax
    movq %rax, -104(%rbp)
    movq -48(%rbp), %rax
    movq %rax, -96(%rbp)
    jmp _kefir_func_divide_f32_label2
_kefir_func_divide_f32_label4:
    stmxcsr -128(%rbp)
    mov -128(%rbp), %rcx
    fnstsw %ax
    or %ecx, %eax
    and $63, %eax
    fldenv -56(%rbp)
    ldmxcsr -28(%rbp)
    stmxcsr -128(%rbp)
    movl -128(%rbp), %ecx
    or %eax, %ecx
    movl %ecx, -128(%rbp)
    ldmxcsr -128(%rbp)
    movq -80(%rbp), %xmm0
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret
__kefir_text_func_divide_f32_end:

divide_f64:
__kefir_text_func_divide_f64_begin:
    push %rbp
    mov %rsp, %rbp
    sub $192, %rsp
    stmxcsr -8(%rbp)
    movq %xmm0, -192(%rbp)
    movq %xmm1, -184(%rbp)
    lea -48(%rbp), %rax
    movq -192(%rbp), %xmm0
    movq %xmm0, (%rax)
    movq -184(%rbp), %xmm0
    movq %xmm0, 8(%rax)
    lea -48(%rbp), %rax
    movq (%rax), %xmm0
    movq %xmm0, -192(%rbp)
    movq 8(%rax), %xmm0
    movq %xmm0, -184(%rbp)
    fnstenv -176(%rbp)
    stmxcsr -148(%rbp)
    fnclex
    mov %rdi, %r10
_kefir_func_divide_f64_label2:
    movq %r10, -128(%rbp)
    mov %r10, %rsi
    lea -144(%rbp), %rdx
    mov $16, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movq -128(%rbp), %r10
    fld1
    fldl -192(%rbp)
    fld %st(0)
    fmul %st(1)
    fldl -184(%rbp)
    fld %st(0)
    fmul %st(1)
    faddp %st(2)
    fxch %st(1)
    fdivrp %st(3)
    fldl -144(%rbp)
    fld %st(0)
    fmul %st(3)
    fxch %st(1)
    fmul %st(2)
    fldl -136(%rbp)
    fld %st(0)
    fmulp %st(4)
    fxch %st(3)
    faddp %st(2)
    fxch %st(1)
    fmul %st(4)
    fstpl -120(%rbp)
    fxch %st(2)
    fmulp %st(1)
    fsubp
    fmulp
    fstpl -112(%rbp)
    movq %r10, -128(%rbp)
    movdqu -144(%rbp), %xmm0
    movdqu %xmm0, -104(%rbp)
    mov %r10, %rsi
    mov $5, %r8
    mov $5, %r9
    mov $16, %rdi
    lea -104(%rbp), %rdx
    leaq -120(%rbp), %rax
    mov %rax, %rcx
    call __atomic_compare_exchange@PLT
    movq -128(%rbp), %r10
    test %al, %al
    jz _kefir_func_divide_f64_label5
    movq -176(%rbp), %rax
    movq %rax, -88(%rbp)
    movq -168(%rbp), %rax
    movq %rax, -80(%rbp)
    movq -160(%rbp), %rax
    movq %rax, -72(%rbp)
    movq -152(%rbp), %rax
    movq %rax, -64(%rbp)
    jmp _kefir_func_divide_f64_label4
_kefir_func_divide_f64_label5:
    mov %r10, %rax
    movq -192(%rbp), %rcx
    movq %rcx, -144(%rbp)
    movq -184(%rbp), %rcx
    movq %rcx, -136(%rbp)
    movq -176(%rbp), %rcx
    movq %rcx, -104(%rbp)
    movq -168(%rbp), %rcx
    movq %rcx, -96(%rbp)
    movq -160(%rbp), %rcx
    movq %rcx, -88(%rbp)
    movq -152(%rbp), %rcx
    movq %rcx, -80(%rbp)
    fnclex
    mov %rax, %r10
    movq -144(%rbp), %rax
    movq %rax, -192(%rbp)
    movq -136(%rbp), %rax
    movq %rax, -184(%rbp)
    movq -104(%rbp), %rax
    movq %rax, -176(%rbp)
    movq -96(%rbp), %rax
    movq %rax, -168(%rbp)
    movq -88(%rbp), %rax
    movq %rax, -160(%rbp)
    movq -80(%rbp), %rax
    movq %rax, -152(%rbp)
    jmp _kefir_func_divide_f64_label2
_kefir_func_divide_f64_label4:
    stmxcsr -192(%rbp)
    mov -192(%rbp), %rcx
    fnstsw %ax
    or %ecx, %eax
    and $63, %eax
    fldenv -88(%rbp)
    ldmxcsr -60(%rbp)
    stmxcsr -192(%rbp)
    movl -192(%rbp), %ecx
    or %eax, %ecx
    movl %ecx, -192(%rbp)
    ldmxcsr -192(%rbp)
    movq -120(%rbp), %xmm0
    movq -112(%rbp), %xmm1
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret
__kefir_text_func_divide_f64_end:

multiply_f32:
__kefir_text_func_multiply_f32_begin:
    push %rbp
    mov %rsp, %rbp
    sub $128, %rsp
    stmxcsr -8(%rbp)
    movq %xmm0, -128(%rbp)
    lea -24(%rbp), %rax
    movq -128(%rbp), %xmm0
    movq %xmm0, (%rax)
    lea -24(%rbp), %rax
    movq (%rax), %xmm0
    movq %xmm0, -128(%rbp)
    fnstenv -120(%rbp)
    stmxcsr -92(%rbp)
    fnclex
    mov %rdi, %r10
_kefir_func_multiply_f32_label2:
    movq %r10, -80(%rbp)
    mov %r10, %rsi
    lea -88(%rbp), %rdx
    mov $8, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movq -80(%rbp), %r10
    movq -88(%rbp), %xmm0
    movq -128(%rbp), %xmm1
    movaps %xmm1, %xmm2
    shufps $160, %xmm1, %xmm2
    mulps %xmm0, %xmm2
    xorps __kefir_constant_complex_float32_mul(%rip), %xmm0
    shufps $177, %xmm0, %xmm0
    shufps $245, %xmm1, %xmm1
    mulps %xmm1, %xmm0
    addps %xmm2, %xmm0
    movq %xmm0, -80(%rbp)
    movq %r10, -64(%rbp)
    movq -88(%rbp), %rax
    movq %rax, -72(%rbp)
    mov %r10, %rsi
    mov $5, %r8
    mov $5, %r9
    mov $8, %rdi
    lea -72(%rbp), %rdx
    leaq -80(%rbp), %rax
    mov %rax, %rcx
    call __atomic_compare_exchange@PLT
    movq -64(%rbp), %r10
    test %al, %al
    jz _kefir_func_multiply_f32_label5
    movq -120(%rbp), %rax
    movq %rax, -56(%rbp)
    movq -112(%rbp), %rax
    movq %rax, -48(%rbp)
    movq -104(%rbp), %rax
    movq %rax, -40(%rbp)
    movq -96(%rbp), %rax
    movq %rax, -32(%rbp)
    jmp _kefir_func_multiply_f32_label4
_kefir_func_multiply_f32_label5:
    mov %r10, %rax
    movq -128(%rbp), %rcx
    movq %rcx, -88(%rbp)
    movq -120(%rbp), %rcx
    movq %rcx, -72(%rbp)
    movq -112(%rbp), %rcx
    movq %rcx, -64(%rbp)
    movq -104(%rbp), %rcx
    movq %rcx, -56(%rbp)
    movq -96(%rbp), %rcx
    movq %rcx, -48(%rbp)
    fnclex
    mov %rax, %r10
    movq -88(%rbp), %rax
    movq %rax, -128(%rbp)
    movq -72(%rbp), %rax
    movq %rax, -120(%rbp)
    movq -64(%rbp), %rax
    movq %rax, -112(%rbp)
    movq -56(%rbp), %rax
    movq %rax, -104(%rbp)
    movq -48(%rbp), %rax
    movq %rax, -96(%rbp)
    jmp _kefir_func_multiply_f32_label2
_kefir_func_multiply_f32_label4:
    stmxcsr -128(%rbp)
    mov -128(%rbp), %rcx
    fnstsw %ax
    or %ecx, %eax
    and $63, %eax
    fldenv -56(%rbp)
    ldmxcsr -28(%rbp)
    stmxcsr -128(%rbp)
    movl -128(%rbp), %ecx
    or %eax, %ecx
    movl %ecx, -128(%rbp)
    ldmxcsr -128(%rbp)
    movq -80(%rbp), %xmm0
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret
__kefir_text_func_multiply_f32_end:

multiply_f64:
__kefir_text_func_multiply_f64_begin:
    push %rbp
    mov %rsp, %rbp
    sub $192, %rsp
    stmxcsr -8(%rbp)
    movq %xmm0, -192(%rbp)
    movq %xmm1, -184(%rbp)
    lea -48(%rbp), %rax
    movq -192(%rbp), %xmm0
    movq %xmm0, (%rax)
    movq -184(%rbp), %xmm0
    movq %xmm0, 8(%rax)
    lea -48(%rbp), %rax
    movq (%rax), %xmm0
    movq %xmm0, -192(%rbp)
    movq 8(%rax), %xmm0
    movq %xmm0, -184(%rbp)
    fnstenv -176(%rbp)
    stmxcsr -148(%rbp)
    fnclex
    mov %rdi, %r10
_kefir_func_multiply_f64_label2:
    movq %r10, -128(%rbp)
    mov %r10, %rsi
    lea -144(%rbp), %rdx
    mov $16, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movq -128(%rbp), %r10
    movq -144(%rbp), %xmm0
    movq -136(%rbp), %xmm1
    movq -192(%rbp), %xmm2
    movq -184(%rbp), %xmm3
    unpcklpd %xmm1, %xmm0
    movaps %xmm0, %xmm1
    xorps __kefir_constant_complex_float64_mul(%rip), %xmm1
    shufpd $1, %xmm1, %xmm1
    unpcklpd %xmm2, %xmm2
    unpcklpd %xmm3, %xmm3
    mulpd %xmm0, %xmm2
    mulpd %xmm1, %xmm3
    addpd %xmm2, %xmm3
    movaps %xmm3, %xmm0
    movaps %xmm3, %xmm1
    unpckhpd %xmm3, %xmm0
    movq %xmm1, -120(%rbp)
    movq %xmm0, -112(%rbp)
    movq %r10, -128(%rbp)
    movdqu -144(%rbp), %xmm0
    movdqu %xmm0, -104(%rbp)
    mov %r10, %rsi
    mov $5, %r8
    mov $5, %r9
    mov $16, %rdi
    lea -104(%rbp), %rdx
    leaq -120(%rbp), %rax
    mov %rax, %rcx
    call __atomic_compare_exchange@PLT
    movq -128(%rbp), %r10
    test %al, %al
    jz _kefir_func_multiply_f64_label5
    movq -176(%rbp), %rax
    movq %rax, -88(%rbp)
    movq -168(%rbp), %rax
    movq %rax, -80(%rbp)
    movq -160(%rbp), %rax
    movq %rax, -72(%rbp)
    movq -152(%rbp), %rax
    movq %rax, -64(%rbp)
    jmp _kefir_func_multiply_f64_label4
_kefir_func_multiply_f64_label5:
    mov %r10, %rax
    movq -192(%rbp), %rcx
    movq %rcx, -144(%rbp)
    movq -184(%rbp), %rcx
    movq %rcx, -136(%rbp)
    movq -176(%rbp), %rcx
    movq %rcx, -104(%rbp)
    movq -168(%rbp), %rcx
    movq %rcx, -96(%rbp)
    movq -160(%rbp), %rcx
    movq %rcx, -88(%rbp)
    movq -152(%rbp), %rcx
    movq %rcx, -80(%rbp)
    fnclex
    mov %rax, %r10
    movq -144(%rbp), %rax
    movq %rax, -192(%rbp)
    movq -136(%rbp), %rax
    movq %rax, -184(%rbp)
    movq -104(%rbp), %rax
    movq %rax, -176(%rbp)
    movq -96(%rbp), %rax
    movq %rax, -168(%rbp)
    movq -88(%rbp), %rax
    movq %rax, -160(%rbp)
    movq -80(%rbp), %rax
    movq %rax, -152(%rbp)
    jmp _kefir_func_multiply_f64_label2
_kefir_func_multiply_f64_label4:
    stmxcsr -192(%rbp)
    mov -192(%rbp), %rcx
    fnstsw %ax
    or %ecx, %eax
    and $63, %eax
    fldenv -88(%rbp)
    ldmxcsr -60(%rbp)
    stmxcsr -192(%rbp)
    movl -192(%rbp), %ecx
    or %eax, %ecx
    movl %ecx, -192(%rbp)
    ldmxcsr -192(%rbp)
    movq -120(%rbp), %xmm0
    movq -112(%rbp), %xmm1
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret
__kefir_text_func_multiply_f64_end:

subtract_f32:
__kefir_text_func_subtract_f32_begin:
    push %rbp
    mov %rsp, %rbp
    sub $128, %rsp
    stmxcsr -8(%rbp)
    movq %xmm0, -128(%rbp)
    lea -24(%rbp), %rax
    movq -128(%rbp), %xmm0
    movq %xmm0, (%rax)
    lea -24(%rbp), %rax
    movq (%rax), %xmm0
    movq %xmm0, -128(%rbp)
    fnstenv -120(%rbp)
    stmxcsr -92(%rbp)
    fnclex
    mov %rdi, %r10
_kefir_func_subtract_f32_label2:
    movq %r10, -80(%rbp)
    mov %r10, %rsi
    lea -88(%rbp), %rdx
    mov $8, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movq -80(%rbp), %r10
    movd -88(%rbp), %xmm0
    movd -84(%rbp), %xmm1
    subss -128(%rbp), %xmm0
    subss -124(%rbp), %xmm1
    movd %xmm0, -80(%rbp)
    movd %xmm1, -76(%rbp)
    movq %r10, -64(%rbp)
    movq -88(%rbp), %rax
    movq %rax, -72(%rbp)
    mov %r10, %rsi
    mov $5, %r8
    mov $5, %r9
    mov $8, %rdi
    lea -72(%rbp), %rdx
    leaq -80(%rbp), %rax
    mov %rax, %rcx
    call __atomic_compare_exchange@PLT
    movq -64(%rbp), %r10
    test %al, %al
    jz _kefir_func_subtract_f32_label5
    movq -120(%rbp), %rax
    movq %rax, -56(%rbp)
    movq -112(%rbp), %rax
    movq %rax, -48(%rbp)
    movq -104(%rbp), %rax
    movq %rax, -40(%rbp)
    movq -96(%rbp), %rax
    movq %rax, -32(%rbp)
    jmp _kefir_func_subtract_f32_label4
_kefir_func_subtract_f32_label5:
    mov %r10, %rax
    movq -128(%rbp), %rcx
    movq %rcx, -88(%rbp)
    movq -120(%rbp), %rcx
    movq %rcx, -72(%rbp)
    movq -112(%rbp), %rcx
    movq %rcx, -64(%rbp)
    movq -104(%rbp), %rcx
    movq %rcx, -56(%rbp)
    movq -96(%rbp), %rcx
    movq %rcx, -48(%rbp)
    fnclex
    mov %rax, %r10
    movq -88(%rbp), %rax
    movq %rax, -128(%rbp)
    movq -72(%rbp), %rax
    movq %rax, -120(%rbp)
    movq -64(%rbp), %rax
    movq %rax, -112(%rbp)
    movq -56(%rbp), %rax
    movq %rax, -104(%rbp)
    movq -48(%rbp), %rax
    movq %rax, -96(%rbp)
    jmp _kefir_func_subtract_f32_label2
_kefir_func_subtract_f32_label4:
    stmxcsr -128(%rbp)
    mov -128(%rbp), %rcx
    fnstsw %ax
    or %ecx, %eax
    and $63, %eax
    fldenv -56(%rbp)
    ldmxcsr -28(%rbp)
    stmxcsr -128(%rbp)
    movl -128(%rbp), %ecx
    or %eax, %ecx
    movl %ecx, -128(%rbp)
    ldmxcsr -128(%rbp)
    movq -80(%rbp), %xmm0
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret
__kefir_text_func_subtract_f32_end:

subtract_f64:
__kefir_text_func_subtract_f64_begin:
    push %rbp
    mov %rsp, %rbp
    sub $192, %rsp
    stmxcsr -8(%rbp)
    movq %xmm0, -192(%rbp)
    movq %xmm1, -184(%rbp)
    lea -48(%rbp), %rax
    movq -192(%rbp), %xmm0
    movq %xmm0, (%rax)
    movq -184(%rbp), %xmm0
    movq %xmm0, 8(%rax)
    lea -48(%rbp), %rax
    movq (%rax), %xmm0
    movq %xmm0, -192(%rbp)
    movq 8(%rax), %xmm0
    movq %xmm0, -184(%rbp)
    fnstenv -176(%rbp)
    stmxcsr -148(%rbp)
    fnclex
    mov %rdi, %r10
_kefir_func_subtract_f64_label2:
    movq %r10, -128(%rbp)
    mov %r10, %rsi
    lea -144(%rbp), %rdx
    mov $16, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movq -128(%rbp), %r10
    movq -144(%rbp), %xmm0
    movq -136(%rbp), %xmm1
    subsd -192(%rbp), %xmm0
    subsd -184(%rbp), %xmm1
    movq %xmm0, -120(%rbp)
    movq %xmm1, -112(%rbp)
    movq %r10, -128(%rbp)
    movdqu -144(%rbp), %xmm0
    movdqu %xmm0, -104(%rbp)
    mov %r10, %rsi
    mov $5, %r8
    mov $5, %r9
    mov $16, %rdi
    lea -104(%rbp), %rdx
    leaq -120(%rbp), %rax
    mov %rax, %rcx
    call __atomic_compare_exchange@PLT
    movq -128(%rbp), %r10
    test %al, %al
    jz _kefir_func_subtract_f64_label5
    movq -176(%rbp), %rax
    movq %rax, -88(%rbp)
    movq -168(%rbp), %rax
    movq %rax, -80(%rbp)
    movq -160(%rbp), %rax
    movq %rax, -72(%rbp)
    movq -152(%rbp), %rax
    movq %rax, -64(%rbp)
    jmp _kefir_func_subtract_f64_label4
_kefir_func_subtract_f64_label5:
    mov %r10, %rax
    movq -192(%rbp), %rcx
    movq %rcx, -144(%rbp)
    movq -184(%rbp), %rcx
    movq %rcx, -136(%rbp)
    movq -176(%rbp), %rcx
    movq %rcx, -104(%rbp)
    movq -168(%rbp), %rcx
    movq %rcx, -96(%rbp)
    movq -160(%rbp), %rcx
    movq %rcx, -88(%rbp)
    movq -152(%rbp), %rcx
    movq %rcx, -80(%rbp)
    fnclex
    mov %rax, %r10
    movq -144(%rbp), %rax
    movq %rax, -192(%rbp)
    movq -136(%rbp), %rax
    movq %rax, -184(%rbp)
    movq -104(%rbp), %rax
    movq %rax, -176(%rbp)
    movq -96(%rbp), %rax
    movq %rax, -168(%rbp)
    movq -88(%rbp), %rax
    movq %rax, -160(%rbp)
    movq -80(%rbp), %rax
    movq %rax, -152(%rbp)
    jmp _kefir_func_subtract_f64_label2
_kefir_func_subtract_f64_label4:
    stmxcsr -192(%rbp)
    mov -192(%rbp), %rcx
    fnstsw %ax
    or %ecx, %eax
    and $63, %eax
    fldenv -88(%rbp)
    ldmxcsr -60(%rbp)
    stmxcsr -192(%rbp)
    movl -192(%rbp), %ecx
    or %eax, %ecx
    movl %ecx, -192(%rbp)
    ldmxcsr -192(%rbp)
    movq -120(%rbp), %xmm0
    movq -112(%rbp), %xmm1
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret
__kefir_text_func_subtract_f64_end:

__kefir_text_section_end:

.section .rodata
    .align 16
__kefir_constant_complex_float32_mul:
    .long 0
    .long 2147483648
    .long 0
    .long 2147483648
    .align 16
__kefir_constant_complex_float32_div:
    .long 0
    .long 0
    .long 0
    .long 2147483648
    .align 16
__kefir_constant_complex_float64_mul:
    .long 0
    .long 0
    .long 0
    .long 2147483648
