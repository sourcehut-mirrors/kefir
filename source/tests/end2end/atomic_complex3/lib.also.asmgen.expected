.att_syntax
.section .note.GNU-stack,"",%progbits

.global add_f32
.type add_f32, @function
.global add_f64
.type add_f64, @function
.global divide_f32
.type divide_f32, @function
.global divide_f64
.type divide_f64, @function
.global multiply_f32
.type multiply_f32, @function
.global multiply_f64
.type multiply_f64, @function
.global subtract_f32
.type subtract_f32, @function
.global subtract_f64
.type subtract_f64, @function

.section .text
__kefir_text_section_begin:
add_f32:
__kefir_text_func_add_f32_begin:
    push %rbp
    mov %rsp, %rbp
    sub $176, %rsp
    stmxcsr -8(%rbp)
    movaps %xmm0, %xmm5
    shufps $1, %xmm5, %xmm5
    movaps %xmm0, %xmm4
    mov %rdi, %r10
    fnstenv -152(%rbp)
    stmxcsr -124(%rbp)
    fnclex
_kefir_func_add_f32_label1:
    movdqu %xmm4, -120(%rbp)
    movdqu %xmm5, -104(%rbp)
    movq %r10, -88(%rbp)
    mov %r10, %rsi
    lea -176(%rbp), %rdx
    mov $8, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movdqu -120(%rbp), %xmm4
    movdqu -104(%rbp), %xmm5
    movq -88(%rbp), %r10
    movd -176(%rbp), %xmm0
    movd -172(%rbp), %xmm1
    movaps %xmm0, %xmm2
    movaps %xmm1, %xmm3
    addss %xmm4, %xmm2
    addss %xmm5, %xmm3
    movdqu %xmm4, -80(%rbp)
    movdqu %xmm5, -64(%rbp)
    movq %r10, -48(%rbp)
    movdqu %xmm2, -40(%rbp)
    movdqu %xmm3, -24(%rbp)
    movd %xmm0, -176(%rbp)
    movd %xmm1, -172(%rbp)
    movd %xmm2, -168(%rbp)
    movd %xmm3, -164(%rbp)
    mov %r10, %rsi
    mov $5, %r8
    mov $5, %r9
    mov $8, %rdi
    lea -176(%rbp), %rdx
    leaq -168(%rbp), %rax
    mov %rax, %rcx
    call __atomic_compare_exchange@PLT
    movdqu -80(%rbp), %xmm4
    movdqu -64(%rbp), %xmm5
    movq -48(%rbp), %r10
    movdqu -40(%rbp), %xmm2
    movdqu -24(%rbp), %xmm3
    test %al, %al
    jz _kefir_func_add_f32_label3
    stmxcsr -176(%rbp)
    mov -176(%rbp), %rcx
    fnstsw %ax
    or %ecx, %eax
    and $63, %eax
    fldenv -152(%rbp)
    ldmxcsr -124(%rbp)
    stmxcsr -176(%rbp)
    orl %eax, -176(%rbp)
    ldmxcsr -176(%rbp)
    movaps %xmm2, %xmm0
    insertps $16, %xmm3, %xmm0
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret
_kefir_func_add_f32_label3:
    fnclex
    jmp _kefir_func_add_f32_label1
__kefir_text_func_add_f32_end:

add_f64:
__kefir_text_func_add_f64_begin:
    push %rbp
    mov %rsp, %rbp
    sub $208, %rsp
    stmxcsr -8(%rbp)
    movaps %xmm0, %xmm4
    movaps %xmm1, %xmm5
    mov %rdi, %r10
    fnstenv -160(%rbp)
    stmxcsr -132(%rbp)
    fnclex
_kefir_func_add_f64_label1:
    movdqu %xmm4, -128(%rbp)
    movdqu %xmm5, -112(%rbp)
    movq %r10, -96(%rbp)
    mov %r10, %rsi
    lea -208(%rbp), %rdx
    mov $16, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movdqu -128(%rbp), %xmm4
    movdqu -112(%rbp), %xmm5
    movq -96(%rbp), %r10
    movq -208(%rbp), %xmm0
    movq -200(%rbp), %xmm1
    movaps %xmm0, %xmm2
    movaps %xmm1, %xmm3
    addsd %xmm4, %xmm2
    addsd %xmm5, %xmm3
    movdqu %xmm4, -88(%rbp)
    movdqu %xmm5, -72(%rbp)
    movq %r10, -56(%rbp)
    movdqu %xmm2, -48(%rbp)
    movdqu %xmm3, -32(%rbp)
    movq %xmm0, -208(%rbp)
    movq %xmm1, -200(%rbp)
    movq %xmm2, -192(%rbp)
    movq %xmm3, -184(%rbp)
    mov %r10, %rsi
    mov $5, %r8
    mov $5, %r9
    mov $16, %rdi
    lea -208(%rbp), %rdx
    leaq -192(%rbp), %rax
    mov %rax, %rcx
    call __atomic_compare_exchange@PLT
    movdqu -88(%rbp), %xmm4
    movdqu -72(%rbp), %xmm5
    movq -56(%rbp), %r10
    movdqu -48(%rbp), %xmm2
    movdqu -32(%rbp), %xmm3
    test %al, %al
    jz _kefir_func_add_f64_label3
    stmxcsr -208(%rbp)
    mov -208(%rbp), %rcx
    fnstsw %ax
    or %ecx, %eax
    and $63, %eax
    fldenv -160(%rbp)
    ldmxcsr -132(%rbp)
    stmxcsr -208(%rbp)
    orl %eax, -208(%rbp)
    ldmxcsr -208(%rbp)
    movaps %xmm2, %xmm0
    movaps %xmm3, %xmm1
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret
_kefir_func_add_f64_label3:
    fnclex
    jmp _kefir_func_add_f64_label1
__kefir_text_func_add_f64_end:

divide_f32:
__kefir_text_func_divide_f32_begin:
    push %rbp
    mov %rsp, %rbp
    sub $176, %rsp
    stmxcsr -8(%rbp)
    movaps %xmm0, %xmm7
    shufps $1, %xmm7, %xmm7
    movaps %xmm0, %xmm8
    mov %rdi, %r10
    fnstenv -160(%rbp)
    stmxcsr -132(%rbp)
    fnclex
_kefir_func_divide_f32_label1:
    movdqu %xmm8, -120(%rbp)
    movdqu %xmm7, -104(%rbp)
    movq %r10, -88(%rbp)
    mov %r10, %rsi
    lea -176(%rbp), %rdx
    mov $8, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movdqu -120(%rbp), %xmm8
    movdqu -104(%rbp), %xmm7
    movq -88(%rbp), %r10
    movd -176(%rbp), %xmm1
    movd -172(%rbp), %xmm2
    movaps %xmm1, %xmm3
    insertps $16, %xmm2, %xmm3
    movaps %xmm8, %xmm0
    insertps $16, %xmm7, %xmm0
    cvtps2pd %xmm0, %xmm4
    cvtps2pd %xmm3, %xmm3
    movaps %xmm4, %xmm5
    movaps %xmm4, %xmm6
    unpcklpd %xmm4, %xmm5
    mulpd %xmm3, %xmm5
    shufpd $1, %xmm3, %xmm3
    unpckhpd %xmm4, %xmm6
    mulpd %xmm4, %xmm4
    mulpd %xmm6, %xmm3
    movaps %xmm4, %xmm6
    xorps __kefir_constant_complex_float32_div(%rip), %xmm3
    shufpd $1, %xmm4, %xmm6
    addpd %xmm3, %xmm5
    addpd %xmm6, %xmm4
    divpd %xmm4, %xmm5
    cvtpd2ps %xmm5, %xmm0
    movaps %xmm0, %xmm3
    shufps $1, %xmm3, %xmm3
    movdqu %xmm8, -80(%rbp)
    movdqu %xmm7, -64(%rbp)
    movq %r10, -48(%rbp)
    movdqu %xmm0, -40(%rbp)
    movdqu %xmm3, -24(%rbp)
    movd %xmm1, -176(%rbp)
    movd %xmm2, -172(%rbp)
    movd %xmm0, -168(%rbp)
    movd %xmm3, -164(%rbp)
    mov %r10, %rsi
    mov $5, %r8
    mov $5, %r9
    mov $8, %rdi
    lea -176(%rbp), %rdx
    leaq -168(%rbp), %rax
    mov %rax, %rcx
    call __atomic_compare_exchange@PLT
    movdqu -80(%rbp), %xmm8
    movdqu -64(%rbp), %xmm7
    movq -48(%rbp), %r10
    movdqu -40(%rbp), %xmm0
    movdqu -24(%rbp), %xmm3
    test %al, %al
    jz _kefir_func_divide_f32_label3
    stmxcsr -176(%rbp)
    mov -176(%rbp), %rcx
    fnstsw %ax
    or %ecx, %eax
    and $63, %eax
    fldenv -160(%rbp)
    ldmxcsr -132(%rbp)
    stmxcsr -176(%rbp)
    orl %eax, -176(%rbp)
    ldmxcsr -176(%rbp)
    insertps $16, %xmm3, %xmm0
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret
_kefir_func_divide_f32_label3:
    fnclex
    jmp _kefir_func_divide_f32_label1
__kefir_text_func_divide_f32_end:

divide_f64:
__kefir_text_func_divide_f64_begin:
    push %rbp
    mov %rsp, %rbp
    sub $208, %rsp
    fstcw -8(%rbp)
    stmxcsr -16(%rbp)
    movaps %xmm0, %xmm4
    movaps %xmm1, %xmm5
    mov %rdi, %r10
    fnstenv -160(%rbp)
    stmxcsr -132(%rbp)
    fnclex
_kefir_func_divide_f64_label1:
    movdqu %xmm4, -128(%rbp)
    movdqu %xmm5, -112(%rbp)
    movq %r10, -96(%rbp)
    mov %r10, %rsi
    lea -208(%rbp), %rdx
    mov $16, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movdqu -128(%rbp), %xmm4
    movdqu -112(%rbp), %xmm5
    movq -96(%rbp), %r10
    movq -208(%rbp), %xmm2
    movq -200(%rbp), %xmm3
    movq %xmm2, -208(%rbp)
    movq %xmm3, -200(%rbp)
    movq %xmm4, -192(%rbp)
    movq %xmm5, -184(%rbp)
    fld1
    fldl -192(%rbp)
    fld %st(0)
    fmul %st(1)
    fldl -184(%rbp)
    fld %st(0)
    fmul %st(1)
    faddp %st(2)
    fxch %st(1)
    fdivrp %st(3)
    fldl -208(%rbp)
    fld %st(0)
    fmul %st(3)
    fxch %st(1)
    fmul %st(2)
    fldl -200(%rbp)
    fld %st(0)
    fmulp %st(4)
    fxch %st(3)
    faddp %st(2)
    fxch %st(1)
    fmul %st(4)
    fstpl -208(%rbp)
    fxch %st(2)
    fmulp %st(1)
    fsubp
    fmulp
    fstpl -200(%rbp)
    movq -208(%rbp), %xmm0
    movq -200(%rbp), %xmm1
    movdqu %xmm4, -88(%rbp)
    movdqu %xmm5, -72(%rbp)
    movq %r10, -56(%rbp)
    movdqu %xmm0, -48(%rbp)
    movdqu %xmm1, -32(%rbp)
    movq %xmm2, -208(%rbp)
    movq %xmm3, -200(%rbp)
    movq %xmm0, -192(%rbp)
    movq %xmm1, -184(%rbp)
    mov %r10, %rsi
    mov $5, %r8
    mov $5, %r9
    mov $16, %rdi
    lea -208(%rbp), %rdx
    leaq -192(%rbp), %rax
    mov %rax, %rcx
    call __atomic_compare_exchange@PLT
    movdqu -88(%rbp), %xmm4
    movdqu -72(%rbp), %xmm5
    movq -56(%rbp), %r10
    movdqu -48(%rbp), %xmm0
    movdqu -32(%rbp), %xmm1
    test %al, %al
    jz _kefir_func_divide_f64_label3
    stmxcsr -208(%rbp)
    mov -208(%rbp), %rcx
    fnstsw %ax
    or %ecx, %eax
    and $63, %eax
    fldenv -160(%rbp)
    ldmxcsr -132(%rbp)
    stmxcsr -208(%rbp)
    orl %eax, -208(%rbp)
    ldmxcsr -208(%rbp)
    ldmxcsr -16(%rbp)
    fldcw -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret
_kefir_func_divide_f64_label3:
    fnclex
    jmp _kefir_func_divide_f64_label1
__kefir_text_func_divide_f64_end:

multiply_f32:
__kefir_text_func_multiply_f32_begin:
    push %rbp
    mov %rsp, %rbp
    sub $176, %rsp
    stmxcsr -8(%rbp)
    movaps %xmm0, %xmm5
    shufps $1, %xmm5, %xmm5
    movaps %xmm0, %xmm6
    mov %rdi, %r10
    fnstenv -152(%rbp)
    stmxcsr -124(%rbp)
    fnclex
_kefir_func_multiply_f32_label1:
    movdqu %xmm6, -120(%rbp)
    movdqu %xmm5, -104(%rbp)
    movq %r10, -88(%rbp)
    mov %r10, %rsi
    lea -176(%rbp), %rdx
    mov $8, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movdqu -120(%rbp), %xmm6
    movdqu -104(%rbp), %xmm5
    movq -88(%rbp), %r10
    movd -176(%rbp), %xmm0
    movd -172(%rbp), %xmm1
    movaps %xmm0, %xmm2
    insertps $16, %xmm1, %xmm2
    movaps %xmm6, %xmm3
    insertps $16, %xmm5, %xmm3
    movaps %xmm3, %xmm4
    shufps $160, %xmm3, %xmm4
    mulps %xmm2, %xmm4
    xorps __kefir_constant_complex_float32_mul(%rip), %xmm2
    shufps $177, %xmm2, %xmm2
    shufps $245, %xmm3, %xmm3
    mulps %xmm3, %xmm2
    addps %xmm4, %xmm2
    movaps %xmm2, %xmm3
    shufps $1, %xmm3, %xmm3
    movdqu %xmm6, -80(%rbp)
    movdqu %xmm5, -64(%rbp)
    movq %r10, -48(%rbp)
    movdqu %xmm2, -40(%rbp)
    movdqu %xmm3, -24(%rbp)
    movd %xmm0, -176(%rbp)
    movd %xmm1, -172(%rbp)
    movd %xmm2, -168(%rbp)
    movd %xmm3, -164(%rbp)
    mov %r10, %rsi
    mov $5, %r8
    mov $5, %r9
    mov $8, %rdi
    lea -176(%rbp), %rdx
    leaq -168(%rbp), %rax
    mov %rax, %rcx
    call __atomic_compare_exchange@PLT
    movdqu -80(%rbp), %xmm6
    movdqu -64(%rbp), %xmm5
    movq -48(%rbp), %r10
    movdqu -40(%rbp), %xmm2
    movdqu -24(%rbp), %xmm3
    test %al, %al
    jz _kefir_func_multiply_f32_label3
    stmxcsr -176(%rbp)
    mov -176(%rbp), %rcx
    fnstsw %ax
    or %ecx, %eax
    and $63, %eax
    fldenv -152(%rbp)
    ldmxcsr -124(%rbp)
    stmxcsr -176(%rbp)
    orl %eax, -176(%rbp)
    ldmxcsr -176(%rbp)
    movaps %xmm2, %xmm0
    insertps $16, %xmm3, %xmm0
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret
_kefir_func_multiply_f32_label3:
    fnclex
    jmp _kefir_func_multiply_f32_label1
__kefir_text_func_multiply_f32_end:

multiply_f64:
__kefir_text_func_multiply_f64_begin:
    push %rbp
    mov %rsp, %rbp
    sub $208, %rsp
    stmxcsr -8(%rbp)
    movaps %xmm0, %xmm6
    movaps %xmm1, %xmm7
    mov %rdi, %r10
    fnstenv -160(%rbp)
    stmxcsr -132(%rbp)
    fnclex
_kefir_func_multiply_f64_label1:
    movdqu %xmm6, -128(%rbp)
    movdqu %xmm7, -112(%rbp)
    movq %r10, -96(%rbp)
    mov %r10, %rsi
    lea -208(%rbp), %rdx
    mov $16, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movdqu -128(%rbp), %xmm6
    movdqu -112(%rbp), %xmm7
    movq -96(%rbp), %r10
    movq -208(%rbp), %xmm2
    movq -200(%rbp), %xmm3
    movaps %xmm2, %xmm4
    movaps %xmm3, %xmm5
    movaps %xmm6, %xmm0
    movaps %xmm7, %xmm1
    unpcklpd %xmm5, %xmm4
    movaps %xmm4, %xmm5
    xorps __kefir_constant_complex_float64_mul(%rip), %xmm5
    shufpd $1, %xmm5, %xmm5
    unpcklpd %xmm0, %xmm0
    unpcklpd %xmm1, %xmm1
    mulpd %xmm4, %xmm0
    mulpd %xmm5, %xmm1
    addpd %xmm0, %xmm1
    movaps %xmm1, %xmm4
    movaps %xmm1, %xmm0
    unpckhpd %xmm1, %xmm4
    movdqu %xmm6, -88(%rbp)
    movdqu %xmm7, -72(%rbp)
    movq %r10, -56(%rbp)
    movdqu %xmm0, -48(%rbp)
    movdqu %xmm4, -32(%rbp)
    movq %xmm2, -208(%rbp)
    movq %xmm3, -200(%rbp)
    movq %xmm0, -192(%rbp)
    movq %xmm4, -184(%rbp)
    mov %r10, %rsi
    mov $5, %r8
    mov $5, %r9
    mov $16, %rdi
    lea -208(%rbp), %rdx
    leaq -192(%rbp), %rax
    mov %rax, %rcx
    call __atomic_compare_exchange@PLT
    movdqu -88(%rbp), %xmm6
    movdqu -72(%rbp), %xmm7
    movq -56(%rbp), %r10
    movdqu -48(%rbp), %xmm0
    movdqu -32(%rbp), %xmm4
    test %al, %al
    jz _kefir_func_multiply_f64_label3
    stmxcsr -208(%rbp)
    mov -208(%rbp), %rcx
    fnstsw %ax
    or %ecx, %eax
    and $63, %eax
    fldenv -160(%rbp)
    ldmxcsr -132(%rbp)
    stmxcsr -208(%rbp)
    orl %eax, -208(%rbp)
    ldmxcsr -208(%rbp)
    movaps %xmm4, %xmm1
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret
_kefir_func_multiply_f64_label3:
    fnclex
    jmp _kefir_func_multiply_f64_label1
__kefir_text_func_multiply_f64_end:

subtract_f32:
__kefir_text_func_subtract_f32_begin:
    push %rbp
    mov %rsp, %rbp
    sub $176, %rsp
    stmxcsr -8(%rbp)
    movaps %xmm0, %xmm5
    shufps $1, %xmm5, %xmm5
    movaps %xmm0, %xmm4
    mov %rdi, %r10
    fnstenv -152(%rbp)
    stmxcsr -124(%rbp)
    fnclex
_kefir_func_subtract_f32_label1:
    movdqu %xmm4, -120(%rbp)
    movdqu %xmm5, -104(%rbp)
    movq %r10, -88(%rbp)
    mov %r10, %rsi
    lea -176(%rbp), %rdx
    mov $8, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movdqu -120(%rbp), %xmm4
    movdqu -104(%rbp), %xmm5
    movq -88(%rbp), %r10
    movd -176(%rbp), %xmm0
    movd -172(%rbp), %xmm1
    movaps %xmm0, %xmm2
    movaps %xmm1, %xmm3
    subss %xmm4, %xmm2
    subss %xmm5, %xmm3
    movdqu %xmm4, -80(%rbp)
    movdqu %xmm5, -64(%rbp)
    movq %r10, -48(%rbp)
    movdqu %xmm2, -40(%rbp)
    movdqu %xmm3, -24(%rbp)
    movd %xmm0, -176(%rbp)
    movd %xmm1, -172(%rbp)
    movd %xmm2, -168(%rbp)
    movd %xmm3, -164(%rbp)
    mov %r10, %rsi
    mov $5, %r8
    mov $5, %r9
    mov $8, %rdi
    lea -176(%rbp), %rdx
    leaq -168(%rbp), %rax
    mov %rax, %rcx
    call __atomic_compare_exchange@PLT
    movdqu -80(%rbp), %xmm4
    movdqu -64(%rbp), %xmm5
    movq -48(%rbp), %r10
    movdqu -40(%rbp), %xmm2
    movdqu -24(%rbp), %xmm3
    test %al, %al
    jz _kefir_func_subtract_f32_label3
    stmxcsr -176(%rbp)
    mov -176(%rbp), %rcx
    fnstsw %ax
    or %ecx, %eax
    and $63, %eax
    fldenv -152(%rbp)
    ldmxcsr -124(%rbp)
    stmxcsr -176(%rbp)
    orl %eax, -176(%rbp)
    ldmxcsr -176(%rbp)
    movaps %xmm2, %xmm0
    insertps $16, %xmm3, %xmm0
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret
_kefir_func_subtract_f32_label3:
    fnclex
    jmp _kefir_func_subtract_f32_label1
__kefir_text_func_subtract_f32_end:

subtract_f64:
__kefir_text_func_subtract_f64_begin:
    push %rbp
    mov %rsp, %rbp
    sub $208, %rsp
    stmxcsr -8(%rbp)
    movaps %xmm0, %xmm4
    movaps %xmm1, %xmm5
    mov %rdi, %r10
    fnstenv -160(%rbp)
    stmxcsr -132(%rbp)
    fnclex
_kefir_func_subtract_f64_label1:
    movdqu %xmm4, -128(%rbp)
    movdqu %xmm5, -112(%rbp)
    movq %r10, -96(%rbp)
    mov %r10, %rsi
    lea -208(%rbp), %rdx
    mov $16, %rdi
    mov $5, %rcx
    call __atomic_load@PLT
    movdqu -128(%rbp), %xmm4
    movdqu -112(%rbp), %xmm5
    movq -96(%rbp), %r10
    movq -208(%rbp), %xmm0
    movq -200(%rbp), %xmm1
    movaps %xmm0, %xmm2
    movaps %xmm1, %xmm3
    subsd %xmm4, %xmm2
    subsd %xmm5, %xmm3
    movdqu %xmm4, -88(%rbp)
    movdqu %xmm5, -72(%rbp)
    movq %r10, -56(%rbp)
    movdqu %xmm2, -48(%rbp)
    movdqu %xmm3, -32(%rbp)
    movq %xmm0, -208(%rbp)
    movq %xmm1, -200(%rbp)
    movq %xmm2, -192(%rbp)
    movq %xmm3, -184(%rbp)
    mov %r10, %rsi
    mov $5, %r8
    mov $5, %r9
    mov $16, %rdi
    lea -208(%rbp), %rdx
    leaq -192(%rbp), %rax
    mov %rax, %rcx
    call __atomic_compare_exchange@PLT
    movdqu -88(%rbp), %xmm4
    movdqu -72(%rbp), %xmm5
    movq -56(%rbp), %r10
    movdqu -48(%rbp), %xmm2
    movdqu -32(%rbp), %xmm3
    test %al, %al
    jz _kefir_func_subtract_f64_label3
    stmxcsr -208(%rbp)
    mov -208(%rbp), %rcx
    fnstsw %ax
    or %ecx, %eax
    and $63, %eax
    fldenv -160(%rbp)
    ldmxcsr -132(%rbp)
    stmxcsr -208(%rbp)
    orl %eax, -208(%rbp)
    ldmxcsr -208(%rbp)
    movaps %xmm2, %xmm0
    movaps %xmm3, %xmm1
    ldmxcsr -8(%rbp)
    lea (%rbp), %rsp
    pop %rbp
    ret
_kefir_func_subtract_f64_label3:
    fnclex
    jmp _kefir_func_subtract_f64_label1
__kefir_text_func_subtract_f64_end:

__kefir_text_section_end:

.section .rodata
    .align 16
__kefir_constant_complex_float32_mul:
    .long 0
    .long 2147483648
    .long 0
    .long 2147483648
    .align 16
__kefir_constant_complex_float32_div:
    .long 0
    .long 0
    .long 0
    .long 2147483648
    .align 16
__kefir_constant_complex_float64_mul:
    .long 0
    .long 0
    .long 0
    .long 2147483648
